{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "south-valve",
   "metadata": {},
   "source": [
    "https://github.com/Beckschen/TransUNet/blob/main/datasets/dataset_synapse.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "competitive-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import h5py\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-mambo",
   "metadata": {},
   "source": [
    "## Auxiliary functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ordered-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rot_flip(image, label):\n",
    "    k = np.random.randint(0, 4)\n",
    "    image = np.rot90(image, k)\n",
    "    label = np.rot90(label, k)\n",
    "    axis = np.random.randint(0, 2)\n",
    "    image = np.flip(image, axis=axis).copy()\n",
    "    label = np.flip(label, axis=axis).copy()\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def random_rotate(image, label):\n",
    "    angle = np.random.randint(-20, 20)\n",
    "    image = ndimage.rotate(image, angle, order=0, reshape=False)\n",
    "    label = ndimage.rotate(label, angle, order=0, reshape=False)\n",
    "    return image, label\n",
    "\n",
    "\n",
    "class RandomGenerator(object):\n",
    "    def __init__(self, output_size):\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        if random.random() > 0.5:\n",
    "            image, label = random_rot_flip(image, label)\n",
    "        elif random.random() > 0.5:\n",
    "            image, label = random_rotate(image, label)\n",
    "        x, y = image.shape\n",
    "        if x != self.output_size[0] or y != self.output_size[1]:\n",
    "            image = zoom(image, (self.output_size[0] / x, self.output_size[1] / y), order=3)  # why not 3?\n",
    "            label = zoom(label, (self.output_size[0] / x, self.output_size[1] / y), order=0)\n",
    "        image = torch.from_numpy(image.astype(np.float32)).unsqueeze(0)\n",
    "        label = torch.from_numpy(label.astype(np.float32))\n",
    "        sample = {'image': image, 'label': label.long()}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-instrumentation",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fleet-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynapseDataset(Dataset):\n",
    "    def __init__(self, base_dir, list_dir, split, transform=None):\n",
    "        self.transform = transform  # using transform in torch!\n",
    "        self.split = split\n",
    "        self.sample_list = open(os.path.join(list_dir, self.split+'.txt')).readlines()\n",
    "        self.data_dir = base_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sample_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.split == \"train\":\n",
    "            slice_name = self.sample_list[idx].strip('\\n')\n",
    "            data_path = os.path.join(self.data_dir, slice_name+'.npz')\n",
    "            data = np.load(data_path)\n",
    "            image, label = data['image'], data['label']\n",
    "        else:\n",
    "            vol_name = self.sample_list[idx].strip('\\n')\n",
    "            filepath = self.data_dir + \"/{}.npy.h5\".format(vol_name)\n",
    "            data = h5py.File(filepath)\n",
    "            image, label = data['image'][:], data['label'][:]\n",
    "\n",
    "        sample = {'image': image, 'label': label}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        sample['case_name'] = self.sample_list[idx].strip('\\n')\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-eating",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-karma",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils import show_sbs\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "\n",
    "# # ------------------- params --------------------\n",
    "INPUT_SIZE = 256\n",
    "BASE_DIR = \n",
    "LIST_DIR = \n",
    "\n",
    "# TR_BATCH_SIZE = 8\n",
    "# TR_DL_SHUFFLE = True\n",
    "# TR_DL_WORKER = 1\n",
    "\n",
    "# VL_BATCH_SIZE = 12\n",
    "# VL_DL_SHUFFLE = False\n",
    "# VL_DL_WORKER = 1\n",
    "\n",
    "# TE_BATCH_SIZE = 12\n",
    "# TE_DL_SHUFFLE = False\n",
    "# TE_DL_WORKER = 1\n",
    "# # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "\n",
    "# # ----------------- transform ------------------\n",
    "transform = transforms.Compose([\n",
    "    RandomGenerator(output_size=[INPUT_SIZE, INPUT_SIZE])\n",
    "])\n",
    "# # <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "\n",
    "\n",
    "# # ----------------- dataset --------------------\n",
    "# preparing training dataset\n",
    "tr_dataset = SynapseDataset(\n",
    "    base_dir = , \n",
    "    list_dir = , \n",
    "    split=\"train\",\n",
    "    transform=transform\n",
    ")\n",
    "print(\"The length of train set is: {}\".format(len(tr_dataset)))\n",
    "\n",
    "    \n",
    "    \n",
    "# # We consider 1815 samples for training, 259 samples for validation and 520 samples for testing\n",
    "# # !cat ~/deeplearning/skin/Prepare_ISIC2018.py\n",
    "\n",
    "# indices = list(range(len(train_dataset)))\n",
    "\n",
    "# # split indices to: -> train, validation, and test\n",
    "# tr_indices = indices[0:1815]\n",
    "# vl_indices = indices[1815:1815+259]\n",
    "# te_indices = indices[1815+259:2594]\n",
    "\n",
    "# # create new datasets from train dataset as training, validation, and test\n",
    "# tr_dataset = Subset(train_dataset, tr_indices)\n",
    "# vl_dataset = Subset(train_dataset, vl_indices)\n",
    "# te_dataset = Subset(train_dataset, te_indices)\n",
    "\n",
    "import random\n",
    "def worker_init_fn(worker_id):\n",
    "    random.seed(args.seed + worker_id)\n",
    "\n",
    "\n",
    "# # prepare train dataloader\n",
    "trainloader = DataLoader(\n",
    "    tr_dataset, \n",
    "    batch_size=TR_BATCH_SIZE, \n",
    "    shuffle=TR_DL_SHUFFLE, \n",
    "    num_workers=TR_DL_WORKER,\n",
    "    pin_memory=True,\n",
    "    worker_init_fn=worker_init_fn\n",
    ")\n",
    "\n",
    "# # prepare validation dataloader\n",
    "# vl_loader = DataLoader(\n",
    "#     vl_dataset, \n",
    "#     batch_size=VL_BATCH_SIZE, \n",
    "#     shuffle=VL_DL_SHUFFLE, \n",
    "#     num_workers=VL_DL_WORKER,\n",
    "#     pin_memory=True\n",
    "# )\n",
    "\n",
    "# # prepare test dataloader\n",
    "# te_loader = DataLoader(\n",
    "#     te_dataset, \n",
    "#     batch_size=TE_BATCH_SIZE, \n",
    "#     shuffle=TE_DL_SHUFFLE, \n",
    "#     num_workers=TE_DL_WORKER,\n",
    "#     pin_memory=True\n",
    "# )\n",
    "\n",
    "# -------------- test -----------------\n",
    "# test and visualize the input data\n",
    "for batch in tr_loader:\n",
    "    print(\"Training\")\n",
    "    img = batch['image']\n",
    "    msk = batch['label']\n",
    "    show_sbs(img[0], msk[0])\n",
    "    break\n",
    "    \n",
    "# for img, msk in vl_loader:\n",
    "#     print(\"Validation\")\n",
    "#     show_sbs(img[0], msk[0])\n",
    "#     break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_cuda11",
   "language": "python",
   "name": "pytorch_cuda11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
